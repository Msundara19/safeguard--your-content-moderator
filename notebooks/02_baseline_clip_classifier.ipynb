{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7050b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800ff58",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading CLIP model...\")\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "print(f\"âœ… Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e763ac0e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def classify_image_zeroshot(image, labels=[\"safe content\", \"unsafe content\"]):\n",
    "    \"\"\"\n",
    "    Use CLIP's zero-shot capabilities to classify image\n",
    "    \"\"\"\n",
    "    inputs = processor(\n",
    "        text=labels,\n",
    "        images=image,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits_per_image = outputs.logits_per_image\n",
    "        probs = logits_per_image.softmax(dim=1)\n",
    "    \n",
    "    return probs.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae071b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nTesting zero-shot classification...\")\n",
    "\n",
    "# Load dataset from previous notebook or reload\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"FalconLLM/nsfw_image_dataset\", split=\"train\")\n",
    "safe_samples = [item for item in dataset if item['label'] == 'safe'][:5]\n",
    "\n",
    "for idx, sample in enumerate(safe_samples):\n",
    "    img = sample['image']\n",
    "    true_label = sample['label']\n",
    "    \n",
    "    probs = classify_image_zeroshot(img)\n",
    "    pred_label = \"safe\" if probs[0] > probs[1] else \"unsafe\"\n",
    "    confidence = max(probs)\n",
    "    \n",
    "    print(f\"\\nImage {idx+1}:\")\n",
    "    print(f\"  True: {true_label}\")\n",
    "    print(f\"  Predicted: {pred_label} (confidence: {confidence:.2%})\")\n",
    "    print(f\"  Probs: safe={probs[0]:.2%}, unsafe={probs[1]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20e33d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Evaluating on 100 images...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Take balanced subset\n",
    "eval_dataset = dataset.shuffle(seed=42).select(range(100))\n",
    "\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "for item in tqdm(eval_dataset):\n",
    "    img = item['image']\n",
    "    true_label = item['label']\n",
    "    \n",
    "    probs = classify_image_zeroshot(img)\n",
    "    pred_label = \"safe\" if probs[0] > probs[1] else \"unsafe\"\n",
    "    \n",
    "    predictions.append(pred_label)\n",
    "    ground_truth.append(true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b471bc3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BASELINE RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(ground_truth, predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(ground_truth, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['safe', 'unsafe'],\n",
    "            yticklabels=['safe', 'unsafe'])\n",
    "plt.title('Confusion Matrix - CLIP Zero-Shot')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('../results/confusion_matrix_baseline.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7cafd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    'model': model_name,\n",
    "    'approach': 'zero-shot',\n",
    "    'num_samples': len(eval_dataset),\n",
    "    'accuracy': (np.array(predictions) == np.array(ground_truth)).mean(),\n",
    "    'predictions': predictions,\n",
    "    'ground_truth': ground_truth\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../results/baseline_results.json', 'w') as f:\n",
    "    json.dump({k: v for k, v in results.items() if k not in ['predictions', 'ground_truth']}, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Results saved to results/baseline_results.json\")\n",
    "print(f\"\\nðŸŽ¯ Baseline Accuracy: {results['accuracy']:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
